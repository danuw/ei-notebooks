{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7583a486-afd6-42d8-934b-fdb33a6f3362",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Using the Edge Impulse Python SDK with TensorFlow and Keras\n",
    "\n",
    "<!--- Do not modify the markdown for this example directly! It is generated from a notebook in https://github.com/edgeimpulse/notebooks --->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574b4630-cb17-4bab-8866-ba292e1bc2c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://docs.edgeimpulse.com/docs/edge-impulse-python-sdk/01-python-sdk-with-tf-keras\"><img src=\"https://raw.githubusercontent.com/edgeimpulse/notebooks/main/.assets/images/logo-ei-32px.png\" /> View on edgeimpulse.com</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/edgeimpulse/notebooks/blob/main/notebooks/01-python-sdk-with-tf-keras.ipynb\"><img src=\"https://raw.githubusercontent.com/edgeimpulse/notebooks/main/.assets/images/logo-colab-32px.png\" /> Run in Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/edgeimpulse/notebooks/blob/main/notebooks/01-python-sdk-with-tf-keras.ipynb\"><img src=\"https://raw.githubusercontent.com/edgeimpulse/notebooks/main/.assets/images/logo-github-32px.png\" /> View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://raw.githubusercontent.com/edgeimpulse/notebooks/main/notebooks/01-python-sdk-with-tf-keras.ipynb\" download><img src=\"https://raw.githubusercontent.com/edgeimpulse/notebooks/main/.assets/images/icon-download-32px.png\" /> Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867045bb-14c2-41c2-a417-0426470df85b",
   "metadata": {
    "tags": []
   },
   "source": [
    "[TensorFlow](https://www.tensorflow.org/) is an open source library for training machine learning models. [Keras](https://keras.io/) is an open source Python library that makes creating neural networks in TensorFlow much easier. We use these two libraries together to very quickly train a model to identify handwritten digits. From there, we use the Edge Impulse Python SDK library to profile the model to see how inference will perform on a target edge device. Then, we use the SDK again to convert our trained model to a C++ library that can be deployed to an edge hardware platform, such as a microcontroller.\n",
    "\n",
    "Follow the code below to see how to train a simple machine learning model and deploy it to a C++ library using Edge Impulse.\n",
    "\n",
    "To learn more about using the Python SDK, please see: [Edge Impulse Python SDK Overview](https://docs.edgeimpulse.com/docs/edge-impulse-python-sdk/overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0de311a-de4c-4fe1-8dd9-e7b2206217d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have not done so already, install the following dependencies\n",
    "!python -m pip install tensorflow edgeimpulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f85b7c9-e76b-459e-ac37-4b348cbb5906",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 16:17:39.144261: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import edgeimpulse as ei"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aef50a1-0a2d-4743-bfc3-de0a9755a87b",
   "metadata": {
    "tags": []
   },
   "source": [
    "You will need to obtain an API key from an Edge Impulse project. Log into [edgeimpulse.com](https://edgeimpulse.com/) and create a new project. Open the project, navigate to **Dashboard** and click on the **Keys** tab to view your API keys. Double-click on the API key to highlight it, right-click, and select **Copy**.\n",
    "\n",
    "![Copy API key from Edge Impulse project](https://raw.githubusercontent.com/edgeimpulse/notebooks/main/.assets/images/python-sdk-copy-ei-api-key.png)\n",
    "\n",
    "Note that you do not actually need to use the project in the Edge Impulse Studio. We just need the API Key.\n",
    "\n",
    "Paste that API key string in the `ei.API_KEY` value in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3429e02d-5188-4215-97c7-5a50b854b06b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "ei.API_KEY = \"ei_dae2...\" # Change this to your Edge Impulse API key\n",
    "labels = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "num_classes = len(labels)\n",
    "savedmodel_name = \"my_model\"\n",
    "deploy_filename = \"my_model_cpp.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9078d0-d5a5-4a9f-96f1-0faecb4e2b1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train a machine learning model\n",
    "\n",
    "We want to create a classifier that can uniquely identify handwritten digits. To start, we will use TensorFlow and Keras to train a very simple convolutional neural network (CNN) on the classic [MNIST](http://yann.lecun.com/exdb/mnist/) dataset, which consists of handwritten digits from 0 to 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a0abd03-9473-4272-b97d-f59cefa44995",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = keras.utils.normalize(x_train, axis=1)\n",
    "x_test = keras.utils.normalize(x_test, axis=1)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "input_shape = x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba42755e-b13c-4e84-a016-4e4fcf4be9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build the model \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(32, activation='relu', input_shape=input_shape),\n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6ddf625-43c9-40da-9c44-7fbbbea8b572",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 874us/step - loss: 0.4382 - accuracy: 0.8797\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 852us/step - loss: 0.2328 - accuracy: 0.9341\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 843us/step - loss: 0.1881 - accuracy: 0.9459\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 856us/step - loss: 0.1618 - accuracy: 0.9527\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 869us/step - loss: 0.1424 - accuracy: 0.9577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x166cbf400>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc2b0ab6-e2d0-4448-9545-4870e5b2d101",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.15037794411182404\n",
      "Test accuracy: 0.957099974155426\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test set\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test loss: {score[0]}\")\n",
    "print(f\"Test accuracy: {score[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e04b239-80c6-43e0-87e0-e3a41b8457db",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Profile your model\n",
    "\n",
    "To start, we need to list the possible target devices we can use for profiling. We need to pick from this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b622df2-9745-4c93-969f-35de2ff10df6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alif-he',\n",
       " 'alif-hp',\n",
       " 'arduino-nano-33-ble',\n",
       " 'arduino-nicla-vision',\n",
       " 'portenta-h7',\n",
       " 'brainchip-akd1000',\n",
       " 'cortex-m4f-80mhz',\n",
       " 'cortex-m7-216mhz',\n",
       " 'espressif-esp32',\n",
       " 'himax-we-i',\n",
       " 'infineon-cy8ckit-062s2',\n",
       " 'infineon-cy8ckit-062-ble',\n",
       " 'jetson-nano',\n",
       " 'mbp-16-2020',\n",
       " 'nordic-nrf52840-dk',\n",
       " 'nordic-nrf5340-dk',\n",
       " 'nordic-nrf9160-dk',\n",
       " 'raspberry-pi-4',\n",
       " 'raspberry-pi-rp2040',\n",
       " 'renesas-ck-ra6m5',\n",
       " 'renesas-rzv2l-cpu',\n",
       " 'renesas-rzv2l',\n",
       " 'st-iot-discovery-kit',\n",
       " 'wio-terminal',\n",
       " 'silabs-xg24',\n",
       " 'silabs-thunderboard-sense-2',\n",
       " 'sony-spresense',\n",
       " 'synaptics-ka10000',\n",
       " 'ti-launchxl',\n",
       " 'ti-tda4vm']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the available profile target devices\n",
    "ei.model.list_profile_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaaef69-1ba2-4ffd-bbe6-88ca299c8ee7",
   "metadata": {
    "tags": []
   },
   "source": [
    "A common option is the `cortex-m4f-80mhz`, as this is a relatively low-power microcontroller family. From there, we can use the Edge Impulse Python SDK to generate a profile for your model to ensure it fits on your target hardware and meets your timing requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c16e2ab-0c50-483e-8d2e-01c2dd48be23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_2/25d5mmg50rv4kk0qsv654_4r0000gn/T/tmp6bh_ecrj/saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/_2/25d5mmg50rv4kk0qsv654_4r0000gn/T/tmp6bh_ecrj/saved_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target results for float32:\n",
      "===========================\n",
      "{   'device': 'cortex-m4f-80mhz',\n",
      "    'tfliteFileSizeBytes': 103788,\n",
      "    'isSupportedOnMcu': True,\n",
      "    'memory': {   'tflite': {'ram': 10172, 'rom': 135184, 'arenaSize': 9932},\n",
      "                  'eon': {'ram': 7840, 'rom': 112208}},\n",
      "    'timePerInferenceMs': 2}\n",
      "\n",
      "\n",
      "Performance on device types:\n",
      "============================\n",
      "{   'variant': 'float32',\n",
      "    'lowEndMcu': {   'description': 'Estimate for a Cortex-M0+ or similar, '\n",
      "                                    'running at 40MHz',\n",
      "                     'timePerInferenceMs': 64,\n",
      "                     'memory': {   'tflite': {'ram': 10121, 'rom': 130752},\n",
      "                                   'eon': {'ram': 7808, 'rom': 112144}},\n",
      "                     'supported': True},\n",
      "    'highEndMcu': {   'description': 'Estimate for a Cortex-M7 or other '\n",
      "                                     'high-end MCU/DSP, running at 240MHz',\n",
      "                      'timePerInferenceMs': 2,\n",
      "                      'memory': {   'tflite': {'ram': 10172, 'rom': 135184},\n",
      "                                    'eon': {'ram': 7840, 'rom': 112208}},\n",
      "                      'supported': True},\n",
      "    'highEndMcuPlusAccelerator': {   'description': 'Estimate for an MCU plus '\n",
      "                                                    'neural network '\n",
      "                                                    'accelerator',\n",
      "                                     'timePerInferenceMs': 1,\n",
      "                                     'memory': {   'tflite': {   'ram': 10172,\n",
      "                                                                 'rom': 135184},\n",
      "                                                   'eon': {   'ram': 7840,\n",
      "                                                              'rom': 112208}},\n",
      "                                     'supported': True},\n",
      "    'mpu': {   'description': 'Estimate for a Cortex-A72, x86 or other '\n",
      "                              'mid-range microprocessor running at 1.5GHz',\n",
      "               'timePerInferenceMs': 1,\n",
      "               'rom': 103788.0,\n",
      "               'supported': True},\n",
      "    'gpuOrMpuAccelerator': {   'description': 'Estimate for a GPU or high-end '\n",
      "                                              'neural network accelerator',\n",
      "                               'timePerInferenceMs': 1,\n",
      "                               'rom': 103788.0,\n",
      "                               'supported': True}}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Estimate the RAM, ROM, and inference time for our model on the target hardware family\n",
    "try:\n",
    "    profile = ei.model.profile(model=model,\n",
    "                               device='cortex-m4f-80mhz')\n",
    "    print(profile.summary())\n",
    "except Exception as e:\n",
    "    print(f\"Could not profile: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e4bc88-032a-4d8a-8b3a-4cbf2ec5d778",
   "metadata": {},
   "source": [
    "## Deploy your model\n",
    "\n",
    "Once you are happy with the performance of the model, you can deploy it to a number of possible hardware targets. The most generic target is to download a .zip file containing a C++ library containing the inference runtime and your trained model. To do that, we first need to create a Classification object which contains our label strings (and other optional information about the model). These strings will be added to the C++ library metadata so you can access them in your edge application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45a3c73-fbc2-477a-9f8d-04c3e10b1863",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set model information, such as your list of labels\n",
    "model_output_type = ei.model.output_type.Classification(labels=labels)\n",
    "\n",
    "# Create C++ library with trained model\n",
    "deploy_bytes = None\n",
    "try:\n",
    "    \n",
    "    deploy_bytes = ei.model.deploy(model=model,\n",
    "                                   model_output_type = model_output_type,\n",
    "                                   deploy_target='zip')\n",
    "except Exception as e:\n",
    "    print(f\"Could not deploy: {e}\")\n",
    "    \n",
    "# Write the downloaded raw bytes to a file\n",
    "if deploy_bytes:\n",
    "    with open(deploy_filename, 'wb') as f:\n",
    "        f.write(deploy_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddfdb39-215c-4f09-88d6-3e9c75ef3603",
   "metadata": {
    "tags": []
   },
   "source": [
    "Your model C++ library should be downloaded as the file *my_model_cpp.zip* in the same directory as this notebook. You are now ready to use your C++ model in your embedded and edge device application! To use the C++ model for local inference, see our documentation [here](https://docs.edgeimpulse.com/docs/deployment/running-your-impulse-locally)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edgeimpulse-EyjE3PPw-py3.10",
   "language": "python",
   "name": "edgeimpulse-eyje3ppw-py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
